{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPzTIfEfkS4zus9QtMs/yCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zolinad/Topic_Redes_Neurais/blob/main/CNN%20com%20dataset%20MNIST/AV3_modelo_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REDES NEURAIS CONVOLUCIONAIS (CNN)\n",
        "**AVALIAÇÃO 3**: Seguir as instruções no arquivo doc no SIGAA"
      ],
      "metadata": {
        "id": "_bBxYHUk-cJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Código 1 (Mostrar imagens do dataset MNIST)**"
      ],
      "metadata": {
        "id": "Vv6OGK03-JJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lista de nomes para cada classe do dataset MNIST (dígitos de 0 a 9)\n",
        "mnist_class_names = {\n",
        "    0: \"Zero\",\n",
        "    1: \"Um\",\n",
        "    2: \"Dois\",\n",
        "    3: \"Três\",\n",
        "    4: \"Quatro\",\n",
        "    5: \"Cinco\",\n",
        "    6: \"Seis\",\n",
        "    7: \"Sete\",\n",
        "    8: \"Oito\",\n",
        "    9: \"Nove\"\n",
        "}\n",
        "\n",
        "# Carregar o dataset MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Varredura em cada imagem no dataset\n",
        "for i in range(30):  # mostrando apenas 30 imagens do dataset\n",
        "    # Pegar uma imagem do dataset\n",
        "    sample_image = x_train[i]\n",
        "    # Pegar o id da classe associada à imagem\n",
        "    image_class_number = y_train[i]\n",
        "    # Procurar o nome da classe baseado no id da classe\n",
        "    image_class_name = mnist_class_names[image_class_number]\n",
        "\n",
        "    # Plotar a imagem\n",
        "    plt.imshow(sample_image, cmap='gray')  # Usar cmap='gray' para exibir em escala de cinza\n",
        "    # Rotular a imagem\n",
        "    plt.title(image_class_name)\n",
        "    # Mostrar o plot na tela\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "RfOYVRwd-Dmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "fdvWdxv8_ugz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Código 2 (TREINAR uma CNN usando o dataset MNIST)**"
      ],
      "metadata": {
        "id": "h_mHdaLB-IrI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMaGNJOhReh2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path\n",
        "\n",
        "# O dataset MNIST possui 70.000 imagens de números, de 0 a 9.\n",
        "\n",
        "# Carregar o dataset MNIST nos conjuntos de TREINO (60.000)  e de TESTE (10.000)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Ajustar as dimensões do dataset para (28, 28, 1) e normalizar os valores\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Converter os rótulos de classe para vetores one-hot encoded\n",
        "# (necessário para classificação multiclasse)\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "# Criar o modelo de CNN e adicionar as camadas\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "# Camada de ENTRADA explícita, que define o formato da entrada (28x28 e 1 canal)\n",
        "camada_entrada = (ALTURA, LARGURA, Q_CANAL)\n",
        "\n",
        "\n",
        "# DUAS Camadas de convolução com 32 filtros (kernels), com tamanho de kernel 3x3\n",
        "model.add(Conv2D(32, (K, K), padding='same', input_shape = camada_entrada, activation=\"relu\"))\n",
        "model.add(Dropout(0.25))  # dropout deve ser antes do POOLING\n",
        "model.add(Conv2D(32, (K, K), activation=\"relu\"))\n",
        "model.add(Dropout(0.25))  # dropout deve ser antes do POOLING\n",
        "# UMA Camada de Pooling, com matrizes de tamanho 2x2 (janelas de pooling)\n",
        "model.add(MaxPooling2D(pool_size=(P, P)))\n",
        "\n",
        "\n",
        "# + DUAS camadas de Convolução com 64 kernels de tamanho 3x3\n",
        "model.add(Conv2D(64, (K, K), padding='same', activation=\"relu\"))\n",
        "model.add(Dropout(0.25))  # dropout deve ser antes do POOLING\n",
        "model.add(Conv2D(64, (K, K), activation=\"relu\"))\n",
        "model.add(Dropout(0.25))  # dropout deve ser antes do POOLING\n",
        "# + UMA camada de Pooling, com matrizes de tamanho 2x2\n",
        "model.add(MaxPooling2D(pool_size=(P, P)))\n",
        "\n",
        "\n",
        "# Camada de Flattening (achatamento das matrizes)\n",
        "model.add(Flatten())\n",
        "# Exibir o resumo do modelo\n",
        "model_summary = model.summary()\n",
        "# Quatidade de neurônios na camada densa (de acordo com a saída na camada de achatamento (Flatten))\n",
        "camada_densa = int(input(\"Digite a quantidade de neurônios na camada densa: \"))\n",
        "\n",
        "\n",
        "# Deep Learning - Camadas da Rede Neural densa (fully conected)\n",
        "model.add(Dense(camada_densa, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(camada_densa, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(camada_densa, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Camada de saida com 10 classes (de 0 a 9)\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model_summary = model.summary()\n",
        "\n",
        "\n",
        "# Compilar o modelo de uma CNN\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# Treinamento do modelo de uma CNN\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size = 200,  # Aumentando o batch-size reduz-se o tempo de treinamento\n",
        "    epochs = 20,  # Menos épocas evitam overfitting e reduzem o tempo de treinamento\n",
        "    validation_data = (x_test, y_test),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Salvar a estrutura do modelo da rede neural\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Salvar os pesos da rede neural\n",
        "model.save_weights(\"model.weights.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "qH2HmJJz_9h4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Código 3 (CLASSIFICAR os números contidos nas imagens de teste)**"
      ],
      "metadata": {
        "id": "AN1ZBnpt_E8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# As classes do dataset MNIST são simplesmente os dígitos de 0 a 9\n",
        "rotulos_das_classes = {\n",
        "    0: \"Zero\",\n",
        "    1: \"Um\",\n",
        "    2: \"Dois\",\n",
        "    3: \"Três\",\n",
        "    4: \"Quatro\",\n",
        "    5: \"Cinco\",\n",
        "    6: \"Seis\",\n",
        "    7: \"Sete\",\n",
        "    8: \"Oito\",\n",
        "    9: \"Nove\"\n",
        "}\n",
        "\n",
        "# Carregar o arquivo json que contém o modelo estruturado da rede neural\n",
        "f = Path(\"model_structure.json\")\n",
        "model_structure = f.read_text()\n",
        "\n",
        "# Recriar o modelo da rede neural\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Recarregar os pesos treinados do modelo de rede neural\n",
        "model.load_weights(\"model.weights.h5\")\n",
        "\n",
        "# Carregar o dataset MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Carregar uma imagem para teste, redimensionando-a para 28x28 pixels,\n",
        "# como requerido no modelo MNIST.\n",
        "img = image.load_img(\"imagem_de_teste.jpg\", color_mode=\"grayscale\", target_size=(ALTURA, LARGURA))\n",
        "\n",
        "# Converter a imagem para um array numpy e normalizar os valores (0 a 1)\n",
        "image_to_test = image.img_to_array(img) / 255.0\n",
        "\n",
        "# Mostrar a imagem que será testada\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Adicionar uma quarta dimensão à imagem (para representar o batch size, que é esperado pelo Keras)\n",
        "lista_de_imagens = np.expand_dims(image_to_test, axis=0)\n",
        "\n",
        "# Fazer a predição usando o modelo\n",
        "resultado = model.predict(lista_de_imagens)\n",
        "\n",
        "# Já que estamos testando apenas uma imagem, só precisamos checar o primeiro resultado\n",
        "resultado_unico = resultado[0]\n",
        "\n",
        "# Mostrar a probabilidade para todas as classes\n",
        "print(\"Probabilidades para cada classe:\")\n",
        "for i, prob in enumerate(resultado_unico):\n",
        "    print(f\"{rotulos_das_classes[i]}: {prob:.2f}\")\n",
        "\n",
        "# Vamos calcular a classe mais provável.\n",
        "indice_da_classe_mais_provavel = int(np.argmax(resultado_unico))\n",
        "probabilidade_da_classe = resultado_unico[indice_da_classe_mais_provavel]\n",
        "\n",
        "# Pegar o nome da classe mais provável (o dígito)\n",
        "classe = rotulos_das_classes[indice_da_classe_mais_provavel]\n",
        "\n",
        "# Mostrar o resultado da classe mais provável\n",
        "print(f\"\\nEsta imagem mostra o dígito {classe} - Probabilidade: {probabilidade_da_classe:.2f}\")\n"
      ],
      "metadata": {
        "id": "T7wFJlBHRfp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}